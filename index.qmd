---
title: "Bayesian Linear Regression"
author: "Kayla Liana Mota"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---


Packages & Library
```{r}
# Install and load required packages
#install.packages("readxl")  # Install if not already installed
#install.packages("corrplot")  # Install if not already installed
library(readxl)
library(corrplot)

# install.packages("rstanarm") 
library(rstan)
library(rstanarm)
library(ggplot2)
library(bayesplot)

# this option uses multiple cores if they're available
options(mc.cores = parallel::detectCores())
```

Data Input
```{r}
library(readxl)
ledata <- read_excel("C:/Users/kayla/Downloads/Life-Expectancy-Data-Updated.xlsx", col_names = FALSE)
names(ledata) <- c("Country",	"Region",	"Year",	"Infant_deaths",	"Under_five_deaths",	"Adult_mortality",	"Alcohol_consumption",	"Hepatitis_B",	"Measles",	"BMI",	"Polio",	"Diphtheria",	"Incidents_HIV",	"GDP_per_capita",	"Population_mln",	"Thinness_ten_nineteen_years",	"Thinness_five_nine_years",	"Schooling",	"Economy_status_Developed",	"Economy_status_Developing", "Life_expectancy")

revledata <- na.omit(ledata)

var <- c("Infant_deaths",	"Under_five_deaths",	"Adult_mortality",	"Alcohol_consumption",	"Hepatitis_B",	"Measles",	"BMI",	"Polio",	"Diphtheria",	"Incidents_HIV",	"GDP_per_capita",	"Population_mln",	"Thinness_ten_nineteen_years",	"Thinness_five_nine_years",	"Schooling",	"Economy_status_Developed",	"Economy_status_Developing", "Life_expectancy")

ndata1 <- revledata[, var]

cdata1 <- na.omit(ndata1)
print(cdata1)
summary(cdata1)
```

```{r}
qplot(Life_expectancy, Schooling, data = cdata1)
```

```{r}
glm_post1 <- stan_glm(Life_expectancy~Schooling, data=cdata1, family=gaussian)

stan_trace(glm_post1, pars=c("(Intercept)","Schooling","sigma"))

summary(glm_post1)

pp_check(glm_post1) #The dark blue line shows the observed data while the light blue lines are simulations from the posterior predictive distribution.

```

```{r}
# another way to look at posterior predictive checks
ppc_intervals(
  y = cdata1$Life_expectancy,
  yrep = posterior_predict(glm_post1),
  x = cdata1$Schooling)
```

```{r}
stan_hist(glm_post1, pars=c("Schooling"), bins=40)
```

```{r}
post_samps_Schooling <- as.data.frame(glm_post1, pars=c("Schooling"))[,"Schooling"]
mn_Schooling <- mean(post_samps_Schooling) # posterior mean 
ci_Schooling <- quantile(post_samps_Schooling, probs=c(0.05, 0.95)) # posterior 90% interval 

print(mn_Schooling)
print(ci_Schooling)
```

```{r}
glm_fit <- glm(Life_expectancy~Schooling, data=cdata1, family=gaussian)
summary(glm_fit)

prior_summary(glm_post1)

#It can also be helpful to juxtapose intervals from the prior distribution and the posterior distribution to see how the observed data has changed the parameter estimates.
posterior_vs_prior(glm_post1, group_by_parameter = TRUE, pars=c("(Intercept)"))
posterior_vs_prior(glm_post1, group_by_parameter = TRUE, pars=c("Schooling","sigma"))
```


```{r}
glm_post2 <- stan_glm(Life_expectancy~Schooling, data=cdata1, family=gaussian, prior=normal(2, 0.5, autoscale=FALSE))

posterior_vs_prior(glm_post2, pars=c("Schooling"), group_by_parameter = TRUE)
```





## Summary of Articles

#### An introduction to using Bayesian linear regression with clinical data

Within the realm of psychology, the tests utilized in research can be
deceptive. This article explains how opting for the Bayesian method
could yield more precise outcomes compared to frequentist methods.
Throughout the article they are using the data from an
electroencephalogram (EEG) and anxiety study to illustrate Bayesian
models.

Specifically focusing on psychology, the article highlights the
substantial reliance on p-values. This emphasis weakens the attention to
precise predictions, failing to emphasize whether the results are true
or valid. The Bayesian approach requires that researchers make
predictions prior to data analysis. While concerns have been raised
about potential subjectivity in these predictions, the article contends
that research inherently involves subjective decisions throughout the
process. Whether rooted in scientific research or not, these decisions
are influenced by existing literature and chosen methods.

The Bayesian linear method involves multiple steps—essentially,
predicting prior values, inputting collected data, and obtaining
probability in the form of a distribution (posterior distribution). This
distribution is typically different from commonly known probability
distributions. This is where the Markov Chain Monte Carlo method becomes
important, as it simulates random draws from the posterior distribution.

In assessing the adequacy of a model, Bayesian methods typically rely on
two commonly used metrics: the widely applicable information criterion
and the Leave-one-out cross-validation. When examining data, various
assumptions, such as having a non-normal distribution, can be overlooked
with the application of the Bayesian method. Despite its advantages,
there are several challenges associated with using Bayesian methods,
primarily its complexity and the need for a deeper understanding of the
technology and methodologies involved.

#### Linear regression model using Bayesian approach for energy performance of residential building

The article discusses the two commonly used methods for estimating
regression model parameters: the frequentist method (OLS or MLE) and the
Bayesian approach. The Bayesian method is characterized by viewing
parameters as random variables, introducing the concept of prior,
likelihood, and posterior distributions.

The research uses an energy efficiency dataset to predict cooling
equipment needs and utilizes linear regression modeling with Ordinary
Least Square (OLS) and Bayesian approaches. Correlation tests reveal
relationships between independent and dependent variables. The OLS
model, while showing significance, fails typical assumptions, prompting
consideration of the Bayesian approach. Bayesian modeling is conducted
using Gibbs Sampler and Markov Chain Monte Carlo (MCMC) methods. The
comparison of OLS and Bayesian models involves criteria such as RMSE,
MAD, and MAPE. The study concludes that Bayesian regression is more
suitable when standard assumptions are not met.

#### What to believe: Bayesian methods for data analysis

The article highlights the flexibility of Bayesian data analysis,
allowing researchers to adapt models to various data types, such as
dichotomous, metric, or those involving multiple treatment groups.
Unlike traditional null-hypothesis significance testing (NHST), Bayesian
analysis focuses on estimating parameters in a descriptive model without
committing to specific cognitive mechanisms. Bayesian methods eliminate
the need for p-values, offering richer information on parameters,
including correlations and trade-offs. The article encourages a shift to
Bayesian data analysis in cognitive science. The Bayesian model allows
flexible customization to data types, estimating parameters like mean
accuracy and certainty. Credible intervals and parameter correlations
are inherent, and the discussion covers coherent power and replication
probability computation in Bayesian analysis, providing a more realistic
estimate compared to traditional NHST power analysis.

#### Bayesian Analysis Reporting Guidelines (BARG)

In Bayesian analysis, even when utilizing representative or informed
priors, it is crucial to perform a sensitivity analysis to assess the
impact of different prior specifications on the posterior results. This
aims to ensure that the findings are not dependent on the choice of
prior. If results remain consistent across various reasonable priors, it
improves the robustness of the findings; however, if they are highly
sensitive to the prior  the outcomes heavily rely on the assumed prior
conditions.

The widely employed Markov Chain Monte Carlo (MCMC) computational method
in Bayesian analysis involves generating samples from the posterior
distribution of parameters. Confirming the convergence of MCMC chains is
important for result reliability. Evidence of convergence, often
indicated by statistics like the Potential Scale Reduction Factor
(PSRF), provides confidence in the validity of the samples. High
Effective Sample Size (ESS) signifies precise estimates, while low ESS
may result in imprecise estimates. Reporting ESS for each parameter or
derived value aids in assessing result reliability.

For decision-making based on continuous-parameter posterior
distribution, defining and justifying the limits of the Region of
Practical Equivalence (ROPE) is crucial. The ROPE determines the range
of parameter values considered practically equivalent and guides
decisions on the practical importance of parameter estimates. Providing
transparency about the computational approach guarantees that users are
informed about potential limitations.

#### The Application of Bayesian Analysis to Issues in Developmental Research

The application of Bayesian analysis to issues in developmental research
The article explores the advantages of Bayesian analysis over
traditional frequentist methods in statistical inference. It emphasizes
Bayesian analysis as a comprehensive and unified framework, capable of
handling uncertainties with accuracy and interpretability. Moreover, it
highlights Bayesian analysis's compatibility with hierarchical models
and its ability to incorporate prior information effectively,
contrasting it with the less optimal nature of frequentist approaches.
The discussion extends to the computational ease afforded by Bayesian
analysis, particularly with the advent of algorithms like MCMC,
showcasing its versatility and applicability across various analytical
contexts.

The article then discusses the practical application of hierarchical
Bayesian models, particularly in a moral reasoning study with
hierarchical data structures. Through the introduction of mixed models
with random effects and the description of hierarchical Bayesian models,
it illustrates their ability in accommodating heterogeneity and
evaluating the linear relationships in developmental research. The text
concludes with a nod to Lindley's prediction, suggesting that Bayesian
methods are poised to dominate the statistical world in the twenty-first
century.

#### Simple Bayesian Testing of Scientific Expectations in Linear Regression Models

The article introduces a Bayes factor testing method to evaluate
hypotheses in linear regression models, specifically when dealing with
equality and order constraints. Linear regression models are commonly
used in scientific fields like work and organizational psychology,
sociology, and experimental psychology to study the impact of predictor
variables on continuous outcomes. The goal of the proposed Bayes factor
testing is to assist researchers in developing and assessing scientific
theories, providing a flexible and intuitive approach to hypothesis
testing.

In exploratory studies, the article explores whether each predictor
affects the dependent variable and, if so, whether the effect is
positive or negative. The Bayes factor test allows simultaneous testing
of multiple hypotheses with equality and order constraints, helping
researchers quantify evidence for different scenarios. In confirmatory
studies, the paper highlights the importance of testing specific
hypotheses with equality and order constraints based on scientific
expectations. The method enables researchers to compare regression
effects, offering a more informative approach than fixed benchmarks.

The advantages of the Bayes factor testing procedure include its quick
and straightforward analytic expression, applicability to various
hypotheses with equality and ordinal constraints, and reliance on a
default prior without needing external prior knowledge. The default
prior is determined using a small fraction of observed data, making the
method practical and automatic. The 'lmhyp' R-package, introduced in the
paper, implements the Bayes factor testing procedure and can be used
alongside the popular 'lm' package for linear regression analysis. The
paper concludes by illustrating the application of the testing method in
work and organizational psychology and social psychology, highlighting
its potential contributions to empirical research in these fields.

## Methods

\~ Bayesian Linear Regression \~

## Analysis and Results

### Data and Visualization

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Statistical Modeling

```{r}

```

### Conclusion

## References
