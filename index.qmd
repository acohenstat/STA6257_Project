---
title: "Bayesian Networks - Data Science Capstone"
author: "Michael Zeihen, Maxime Martin, Meghan Alexander, Sarah Burns, Seth Henry"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---
```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(rmarkdown)
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```


## Introduction

### What is "Bayesian Network"?

A Bayesian network, also known as a belief network or a probabilistic graphical model, is a representation of a set of variables and their conditional dependencies via a directed acyclic graph (DAG). Each node in the graph represents a random variable, and the edges between the nodes represent probabilistic dependencies among these variables. The primary components of a Bayesian network are:

Nodes: These represent the random variables.

Edges: Directed edges between nodes represent conditional dependencies. If there is an edge from node 
𝐴
A to node 
𝐵
B, 
𝐴
A is a parent of 
𝐵
B, and 
𝐵
B is conditionally dependent on 
𝐴
A.

Conditional Probability Distributions (CPDs): For each node, the CPD defines the probability of the node given its parents in the network.

A simple Bayesian network can be visualized as a directed acyclic graph (DAG) with nodes representing random variables and directed edges representing conditional dependencies between these variables. 

The Bayesian theorem, also known as Bayes' rule, is a fundamental principle in probability theory that describes how to update the probability of a hypothesis based on new evidence. The formula is given by:

𝑃
(
𝐴
∣
𝐵
)
=
𝑃
(
𝐵
∣
𝐴
)
⋅
𝑃
(
𝐴
)
𝑃
(
𝐵
)
P(A∣B)= 
P(B)
P(B∣A)⋅P(A)
​
 

Where:

𝑃
(
𝐴
∣
𝐵
)
P(A∣B) is the posterior probability: the probability of event 
𝐴
A occurring given that 
𝐵
B is true.
𝑃
(
𝐵
∣
𝐴
)
P(B∣A) is the likelihood: the probability of event 
𝐵
B occurring given that 
𝐴
A is true.
𝑃
(
𝐴
)
P(A) is the prior probability: the initial probability of event 
𝐴
A.
𝑃
(
𝐵
)
P(B) is the marginal probability: the total probability of event 
𝐵
B.

Bayesian networks leverage Bayes' theorem to update the probabilities of various hypotheses given new evidence, allowing for probabilistic reasoning and decision-making under uncertainty. The process involves defining the network structure and conditional probabilities, calculating joint and marginal probabilities, and applying Bayes' theorem to infer the posterior probabilities.


## Methods



## Analysis and Results

### Data and Visualization




### Statistical Modeling


### Conclusion

## References
