---
title: "Bayesian Networks - Data Science Capstone"
author: "Michael Zeihen, Maxime Martin, Meghan Alexander, Sarah Burns, Seth Henry"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---
```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(rmarkdown)
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```


## Introduction

### What is "Bayesian Network"?

A Bayesian network, also known as a belief network or a probabilistic graphical model, is a representation of a set of variables and their conditional dependencies via a Directed Acyclic Graph (DAG). [@heckerman1995tutorial] Each node in the graph represents a random variable, and the edges between the nodes represent probabilistic dependencies among these variables. Bayes' theorem is a fundamental concept used in this network. Bayes' thereum describes the probability of an event, based on prior knowledge of conditions that might be related to the event. The formula for Bayes' theorem is:
$$
P(A \mid B) = \frac{P(B \mid A) \cdot P(A)}{P(B)}
$$

A simple Bayesian network can be visualized as a directed acyclic graph (DAG) with nodes representing random variables and directed edges representing conditional dependencies between these variables.[@heckerman1995tutorial] 

<figure style="text-align: center;">
  <img src="img/Simple_Bayesian.png" alt="Alt text" style="display: block; margin: 0 auto; width: 50%;">
  <figcaption>Simple Bayesian Network</figcaption>
</figure>

Bayesian networks leverage Bayes' theorem to update the probabilities of various hypotheses given new evidence, allowing for probabilistic reasoning and decision-making under uncertainty. The process involves defining the network structure and conditional probabilities, calculating joint and marginal probabilities, and applying Bayes' theorem to infer the posterior probabilities.
[@koller2009probabilistic] 

## Methods
Define Variables and Dependencies:

Assign Conditional Probability Tables (CPTs): 

Inference:

Learning: structure and parameter 

## Analysis and Results
Decision Support:

Validation and Sensitivity Analysis:

### Data and Visualization
directed acyclic graph (DAG).

Conditional Probability Tables (CPTs)

Probability Distributions:

### Statistical Modeling


### Conclusion

## References
